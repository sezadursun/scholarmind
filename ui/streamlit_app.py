import os
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"

import streamlit as st
from scholarmind_ui_theme import apply_scholarmind_theme
apply_scholarmind_theme()

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from openai import OpenAI
from openai._exceptions import AuthenticationError, InvalidRequestError

from app.paper_search import search_papers
from app.summarize import summarize_paper, summarize_fulltext
from app.prompts import SYSTEM_MESSAGE
from app.faiss_engine import add_text_to_index, search_similar, suggest_topics_based_on_text
from app.chroma import add_to_memory as add_to_chroma_memory, search_memory
from app.arxiv import search_arxiv
from app.rag_qa_engine import build_index_from_text, answer_with_context
from app.rag_milvus import streamlit_memory_qa_tab
from app.milvus_engine import add_to_milvus
from PyPDF2 import PdfReader

# ğŸ” API Key
st.sidebar.markdown("## ğŸ” OpenAI API Key")
api_key = st.sidebar.text_input("Enter your OpenAI API Key", type="password")
if not api_key:
    st.warning("Please enter your OpenAI API Key in the sidebar to continue.")
    st.stop()

# âœ… MODEL TESTÄ°
with st.sidebar.expander("ğŸ¤– GPT-4 EriÅŸim Testi"):
    if st.button("GPT-4 EriÅŸimini Test Et"):
        try:
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": "Sadece Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kanÄ±tla"}],
                max_tokens=5
            )
            st.success("âœ… GPT-4 modeline eriÅŸiminiz var!")
        except AuthenticationError:
            st.error("âŒ API anahtarÄ±nÄ±z geÃ§ersiz olabilir.")
        except InvalidRequestError as e:
            if "model" in str(e) and "not found" in str(e):
                st.error("ğŸš« GPT-4 modeline eriÅŸiminiz yok.")
            else:
                st.error(f"âš ï¸ Hata: {str(e)}")
        except Exception as e:
            st.error(f"â— Beklenmeyen hata: {str(e)}")

# ğŸ§  ScholarMind
st.title(":brain: ScholarMind")
st.caption("Bilge araÅŸtÄ±rma hafÄ±zanÄ±z. ArayÄ±n, Ã¶zetleyin, hatÄ±rlayÄ±n.")

TAB_LABELS = [
    "ğŸ” Makale Ara", "ğŸ“Œ PDF YÃ¼kle", "ğŸ” GeÃ§miÅŸ AraÅŸtÄ±rmalarÄ±m",
    "ğŸ¥š ArXiv Preprint Arama", "ğŸ“– Makaleye Soru Sor",
    "ğŸ§  HafÄ±zaya DayalÄ± Soru", "ğŸ“Œ PDF'yi HafÄ±zaya Ekle"
]
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs(TAB_LABELS)

# ğŸ” Makale Arama
with tab1:
    query = st.text_input("ğŸ” Konu:", "transformer visual recognition")
    year = st.slider("ğŸ“… Minimum YayÄ±n YÄ±lÄ±", 2000, 2024, 2020)
    limit = st.selectbox("ğŸ“„ KaÃ§ makale getirilsin?", [3, 5, 7, 10], index=1)
    run = st.button("Ara ve Ã–zetle")

    if run:
        with st.spinner("Makaleler aranÄ±yor..."):
            try:
                papers = search_papers(query=query, year=year, limit=limit)
            except Exception as e:
                st.error(f"ğŸ“± Semantic Scholar API hatasÄ±: {str(e)}")
                st.stop()

        if not papers:
            st.warning("â— AradÄ±ÄŸÄ±nÄ±z konuda sonuÃ§ bulunamadÄ±.")
        else:
            st.success(f"{len(papers)} makale bulundu.")
            for idx, paper in enumerate(papers, 1):
                st.markdown(f"## {idx}. {paper['title']}")
                authors = ", ".join([a['name'] for a in paper['authors']])
                st.markdown(f"**Yazarlar:** {authors}  \n**YÄ±l:** {paper['year']}  \n**AlÄ±ntÄ±:** {paper['citationCount']}")
                st.markdown(f"ğŸ”— [Orijinal Makale]({paper['url']})")

                with st.spinner("KÄ±sa Ã¶zet hazÄ±rlanÄ±yor..."):
                    try:
                        short_summary = summarize_paper({
                            "title": paper["title"],
                            "abstract": paper["abstract"]
                        }, api_key)
                        st.success(f"**KÄ±sa Ã–zet:** {short_summary}")
                    except Exception as e:
                        st.error(f"âš ï¸ Ã–zetleme hatasÄ±: {str(e)}")

                combined_text = f"{paper['title']} - {short_summary}"
                add_text_to_index(combined_text, source_id=paper['title'], api_key=api_key)
                add_to_chroma_memory(
                    id=f"{paper['title']}_{idx}",
                    content=combined_text,
                    metadata={"source": "SemanticScholar", "title": paper['title']}
                )

                with st.expander("ğŸ“œ DetaylÄ± Ã–zet (isteÄŸe baÄŸlÄ± aÃ§Ä±lÄ±r)"):
                    with st.spinner("DetaylÄ± Ã¶zet hazÄ±rlanÄ±yor..."):
                        detailed_prompt = f"""
Makale baÅŸlÄ±ÄŸÄ±: {paper['title']}

Ã–zeti: {paper['abstract']}

Bu makaleyi aÅŸaÄŸÄ±daki baÅŸlÄ±klar altÄ±nda detaylÄ±ca analiz et:

1. Problem tanÄ±mÄ±  
2. KullanÄ±lan yÃ¶ntem ve veri  
3. SonuÃ§lar ve katkÄ±lar  
4. Bu Ã§alÄ±ÅŸmanÄ±n Ã¶nem dÃ¼zeyi

Hepsini sade ve akademik bir dille aÃ§Ä±kla (6-10 cÃ¼mle arasÄ±).
"""
                        try:
                            response = client.chat.completions.create(
                                model="gpt-4",
                                messages=[
                                    {"role": "system", "content": SYSTEM_MESSAGE},
                                    {"role": "user", "content": detailed_prompt}
                                ]
                            )
                            st.info(response.choices[0].message.content.strip())
                        except Exception as e:
                            st.error(f"GPT-4 hata: {str(e)}")

                st.markdown("### ğŸ” Benzer Makaleler")
                similar = search_similar(combined_text, top_k=3, api_key=api_key)
                for sim_idx, (chunk, src) in enumerate(similar, 1):
                    st.markdown(f"**{sim_idx}. ({src})**")
                    st.write(f"_{chunk[:300]}..._")

                st.markdown("### ğŸ’¡ Yeni AraÅŸtÄ±rma Konu Ã–nerileri")
                topics = suggest_topics_based_on_text(combined_text, api_key=api_key)
                st.success(topics)

                st.markdown("---")

# ğŸ” GeÃ§miÅŸ AraÅŸtÄ±rmalarÄ±m
with tab3:
    st.subheader("ğŸ” Daha Ã–nce EklediÄŸiniz AraÅŸtÄ±rmalar")
    search_term = st.text_input("ğŸ“… GeÃ§miÅŸte aradÄ±ÄŸÄ±nÄ±z bir konuyu yazÄ±n:")
    if search_term:
        with st.spinner("GeÃ§miÅŸ taranÄ±yor..."):
            results = search_memory(search_term)
            for i, (doc, meta) in enumerate(zip(results["documents"][0], results["metadatas"][0])):
                st.markdown(f"**{i+1}. {meta.get('source', 'Kaynak Yok')}**")
                st.info(doc[:500] + "...")

# ğŸ§ª ArXiv Sekmesi
with tab4:
    st.subheader("ğŸ§ª ArXiv Preprint Arama")
    arxiv_query = st.text_input("ğŸ” ArXiv'te aramak istediÄŸiniz konu:", "self-supervised learning")
    max_results = st.slider("KaÃ§ makale getirilsin?", 1, 10, 5)

    if st.button("ArXiv'te Ara"):
        with st.spinner("arXiv API'den sonuÃ§lar getiriliyor..."):
            arxiv_papers = search_arxiv(arxiv_query, max_results=max_results)

        if not arxiv_papers:
            st.warning("HiÃ§bir preprint bulunamadÄ±.")
        else:
            for i, paper in enumerate(arxiv_papers, 1):
                st.markdown(f"### {i}. {paper['title']}")
                st.markdown(f"**Yazarlar:** {paper['authors']}")
                st.markdown(f"**YayÄ±n Tarihi:** {paper['published']}")
                st.write(f"**Ã–zet:** {paper['summary'][:500]}...")
                st.markdown(f"[ğŸ”— ArXiv Linki]({paper['link']})")
                st.markdown("---")

# ğŸ“– Makale Q&A Sekmesi
with tab5:
    st.subheader("ğŸ“– YÃ¼klediÄŸiniz makaleye soru sorun")

    uploaded_file = st.file_uploader("ğŸ“Œ PDF yÃ¼kleyin", type=["pdf"])
    question = st.text_input("â“ Bu makaleyle ilgili ne Ã¶ÄŸrenmek istiyorsunuz?", "")

    if uploaded_file and question and st.button("ğŸ§  Soruyu YanÄ±tla"):
        with st.spinner("PDF okunuyor ve analiz ediliyor..."):
            try:
                pdf_reader = PdfReader(uploaded_file)
                full_text = ""
                for page in pdf_reader.pages:
                    full_text += page.extract_text() or ""

                if len(full_text) < 100:
                    st.warning("Bu PDF'den yeterince metin Ã§Ä±karÄ±lamadÄ±.")
                else:
                    build_index_from_text(full_text)
                    with st.spinner("YanÄ±t oluÅŸturuluyor..."):
                        answer = answer_with_context(question, api_key)
                        st.success("âœ… YanÄ±t:")
                        st.write(answer)
            except Exception as e:
                st.error(f"Hata oluÅŸtu: {str(e)}")

# ğŸ§  HafÄ±zaya DayalÄ± Soru Sekmesi
with tab6:
    streamlit_memory_qa_tab(api_key)

# ğŸ“Œ PDF'yi Milvus HafÄ±zasÄ±na Ekle Sekmesi
with tab7:
    st.subheader("ğŸ“Œ PDF'yi Milvus HafÄ±zasÄ±na Ekle")

    user_id = st.text_input("ğŸ‘¤ KullanÄ±cÄ± ID:", value="demo-user")
    uploaded_file = st.file_uploader("ğŸ“ PDF yÃ¼kleyin", type=["pdf"], key="milvus_pdf")

    if uploaded_file and user_id and st.button("ğŸ’¾ HafÄ±zaya Kaydet"):
        with st.spinner("PDF okunuyor ve embedding Milvus'a kaydediliyor..."):
            try:
                pdf_reader = PdfReader(uploaded_file)
                full_text = ""
                for page in pdf_reader.pages:
                    full_text += page.extract_text() or ""

                if len(full_text.strip()) < 100:
                    st.warning("Bu PDF'den yeterince metin Ã§Ä±karÄ±lamadÄ±.")
                else:
                    title = uploaded_file.name.replace(".pdf", "")
                    add_to_milvus(user_id=user_id, title=title, text=full_text, api_key=api_key)
                    st.success(f"âœ… '{title}' baÅŸlÄ±klÄ± iÃ§erik hafÄ±zaya eklendi!")
            except Exception as e:
                st.error(f"Hata oluÅŸtu: {str(e)}")
