import os
os.environ["STREAMLIT_SERVER_FILE_WATCHER_TYPE"] = "none"

import streamlit as st
from scholarmind_ui_theme import apply_scholarmind_theme
apply_scholarmind_theme()

import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from openai import OpenAI
from app.paper_search import search_papers
from app.summarize import summarize_paper, summarize_fulltext
from app.prompts import SYSTEM_MESSAGE
from app.faiss_engine import add_text_to_index, search_similar, suggest_topics_based_on_text
from app.chroma import add_to_memory as add_to_chroma_memory, search_memory
from app.arxiv import search_arxiv
from app.rag_qa_engine import build_index_from_text, answer_with_context
from app.rag_milvus import streamlit_memory_qa_tab
from app.milvus_engine import add_to_milvus
from app.milvus_engine import list_titles
from PyPDF2 import PdfReader

# ğŸ” API Key
st.sidebar.markdown("## ğŸ” OpenAI API Key")
api_key = st.sidebar.text_input("Enter your OpenAI API Key", type="password")
if not api_key:
    st.warning("Please enter your OpenAI API Key in the sidebar to continue.")
    st.stop()

# âœ… GPT-4o MODEL TESTÄ°
with st.sidebar.expander("ğŸ¤– GPT-4o EriÅŸim Testi"):
    if st.button("GPT-4o EriÅŸimini Test Et"):
        try:
            client = OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[{"role": "user", "content": "Sadece Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± kanÄ±tla"}],
                max_tokens=5
            )
            st.success("âœ… GPT-4o modeline eriÅŸiminiz var!")
        except Exception as e:
            if "Incorrect API key" in str(e) or "401" in str(e):
                st.error("âŒ API anahtarÄ±nÄ±z geÃ§ersiz olabilir.")
            elif "model" in str(e) and "not found" in str(e):
                st.error("ğŸš« GPT-4o modeline eriÅŸiminiz yok.")
            else:
                st.error(f"âš ï¸ Bilinmeyen hata: {str(e)}")

# ğŸ§  ScholarMind

st.markdown(
    """
    <style>
    .stTabs [data-baseweb="tab-list"] {
        flex-wrap: nowrap;
        overflow-x: auto;
        -webkit-overflow-scrolling: touch;
        scrollbar-width: none;
        gap: 0.4rem;
    }

    .stTabs [data-baseweb="tab-list"]::-webkit-scrollbar {
        display: none;
    }

    .stTabs [data-baseweb="tab"] {
        background-color: #F0F0F0;
        color: #333;
        padding: 0.6rem 1rem;
        border-radius: 10px;
        border: 1px solid #d0d0d0;
        font-weight: 600;
        font-size: 1rem;
        transition: all 0.3s ease;
        white-space: nowrap;
        flex-shrink: 0;
    }

    .stTabs [aria-selected="true"] {
        background-color: #4B3F72 !important;
        color: white !important;
        border: 2px solid #4B3F72;
        box-shadow: inset 0 -4px 0 #F44336;
    }

    .stTabs [data-baseweb="tab"]:hover {
        background-color: #E0E0E0;
        cursor: pointer;
    }
    </style>
    """,
    unsafe_allow_html=True
)


st.title(":brain: ScholarMind")
st.caption("Bilge araÅŸtÄ±rma hafÄ±zanÄ±z. ArayÄ±n, Ã¶zetleyin, hatÄ±rlayÄ±n.")

TAB_LABELS = [
    "ğŸ” Ara", "âª GeÃ§miÅŸ", "ğŸ¥š ArXiv", "ğŸ“– Soru Sor", "ğŸ§  HafÄ±zadan Sor", "ğŸ§¾ PDF â• HafÄ±za", "ğŸ“‚ BaÅŸlÄ±klarÄ± GÃ¶r"
]
tab1, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs(TAB_LABELS)


# ğŸ” Makale Arama
with tab1:
    query = st.text_input("ğŸ” Konu:", "transformer visual recognition")
    year = st.slider("ğŸ“… Minimum YayÄ±n YÄ±lÄ±", 2000, 2024, 2020)
    limit = st.selectbox("ğŸ“„ KaÃ§ makale getirilsin?", [3, 5, 7, 10], index=1)
    run = st.button("Ara ve Ã–zetle")

    if run:
        with st.spinner("Makaleler aranÄ±yor..."):
            try:
                papers = search_papers(query=query, year=year, limit=limit)
            except Exception as e:
                st.error(f"ğŸ“± Semantic Scholar API hatasÄ±: {str(e)}")
                st.stop()

        if not papers:
            st.warning("â— AradÄ±ÄŸÄ±nÄ±z konuda sonuÃ§ bulunamadÄ±.")
        else:
            st.success(f"{len(papers)} makale bulundu.")
            for idx, paper in enumerate(papers, 1):
                st.markdown(f"## {idx}. {paper['title']}")
                authors = ", ".join([a['name'] for a in paper['authors']])
                st.markdown(f"**Yazarlar:** {authors}  \n**YÄ±l:** {paper['year']}  \n**AlÄ±ntÄ±:** {paper['citationCount']}")
                st.markdown(f"ğŸ”— [Orijinal Makale]({paper['url']})")

                with st.spinner("KÄ±sa Ã¶zet hazÄ±rlanÄ±yor..."):
                    try:
                        short_summary = summarize_paper({
                            "title": paper["title"],
                            "abstract": paper["abstract"]
                        }, api_key)
                        st.success(f"**KÄ±sa Ã–zet:** {short_summary}")
                    except Exception as e:
                        st.error(f"âš ï¸ Ã–zetleme hatasÄ±: {str(e)}")

                combined_text = f"{paper['title']} - {short_summary}"
                add_text_to_index(combined_text, source_id=paper['title'], api_key=api_key)
                add_to_chroma_memory(
                    id=f"{paper['title']}_{idx}",
                    content=combined_text,
                    metadata={"source": "SemanticScholar", "title": paper['title']}
                )

                with st.expander("ğŸ“œ DetaylÄ± Ã–zet (isteÄŸe baÄŸlÄ± aÃ§Ä±lÄ±r)"):
                    with st.spinner("DetaylÄ± Ã¶zet hazÄ±rlanÄ±yor..."):
                        detailed_prompt = f"""
Makale baÅŸlÄ±ÄŸÄ±: {paper['title']}

Ã–zeti: {paper['abstract']}

Bu makaleyi aÅŸaÄŸÄ±daki baÅŸlÄ±klar altÄ±nda detaylÄ±ca analiz et:

1. Problem tanÄ±mÄ±  
2. KullanÄ±lan yÃ¶ntem ve veri  
3. SonuÃ§lar ve katkÄ±lar  
4. Bu Ã§alÄ±ÅŸmanÄ±n Ã¶nem dÃ¼zeyi

Hepsini sade ve akademik bir dille aÃ§Ä±kla (6-10 cÃ¼mle arasÄ±).
"""
                        try:
                            response = client.chat.completions.create(
                                model="gpt-4o",
                                messages=[
                                    {"role": "system", "content": SYSTEM_MESSAGE},
                                    {"role": "user", "content": detailed_prompt}
                                ]
                            )
                            st.info(response.choices[0].message.content.strip())
                        except Exception as e:
                            st.error(f"GPT-4o hata: {str(e)}")

                st.markdown("### ğŸ” Benzer Makaleler")
                similar = search_similar(combined_text, top_k=3, api_key=api_key)
                for sim_idx, (chunk, src) in enumerate(similar, 1):
                    st.markdown(f"**{sim_idx}. ({src})**")
                    st.write(f"_{chunk[:300]}..._")

                st.markdown("### ğŸ’¡ Yeni AraÅŸtÄ±rma Konu Ã–nerileri")
                topics = suggest_topics_based_on_text(combined_text, api_key=api_key)
                st.success(topics)

                st.markdown("---")

# ğŸ” GeÃ§miÅŸ AraÅŸtÄ±rmalarÄ±m
with tab3:
    st.subheader("ğŸ” Daha Ã–nce EklediÄŸiniz AraÅŸtÄ±rmalar")
    search_term = st.text_input("ğŸ“… GeÃ§miÅŸte aradÄ±ÄŸÄ±nÄ±z bir konuyu yazÄ±n:")
    if search_term:
        with st.spinner("GeÃ§miÅŸ taranÄ±yor..."):
            results = search_memory(search_term)
            for i, (doc, meta) in enumerate(zip(results["documents"][0], results["metadatas"][0])):
                st.markdown(f"**{i+1}. {meta.get('source', 'Kaynak Yok')}**")
                st.info(doc[:500] + "...")

# ğŸ§ª ArXiv Sekmesi
with tab4:
    st.subheader("ğŸ§ª ArXiv Preprint Arama")
    arxiv_query = st.text_input("ğŸ” ArXiv'te aramak istediÄŸiniz konu:", "self-supervised learning")
    max_results = st.slider("KaÃ§ makale getirilsin?", 1, 10, 5)

    if st.button("ArXiv'te Ara"):
        with st.spinner("arXiv API'den sonuÃ§lar getiriliyor..."):
            arxiv_papers = search_arxiv(arxiv_query, max_results=max_results)

        if not arxiv_papers:
            st.warning("HiÃ§bir preprint bulunamadÄ±.")
        else:
            for i, paper in enumerate(arxiv_papers, 1):
                st.markdown(f"### {i}. {paper['title']}")
                st.markdown(f"**Yazarlar:** {paper['authors']}")
                st.markdown(f"**YayÄ±n Tarihi:** {paper['published']}")
                st.write(f"**Ã–zet:** {paper['summary'][:500]}...")
                st.markdown(f"[ğŸ”— ArXiv Linki]({paper['link']})")
                st.markdown("---")

# ğŸ“– Makale Q&A Sekmesi
with tab5:
    st.subheader("ğŸ“– YÃ¼klediÄŸiniz makaleye soru sorun")

    uploaded_file = st.file_uploader("ğŸ“Œ PDF yÃ¼kleyin", type=["pdf"])
    question = st.text_input("â“ Bu makaleyle ilgili ne Ã¶ÄŸrenmek istiyorsunuz?", "")

    if uploaded_file and question and st.button("ğŸ§  Soruyu YanÄ±tla"):
        with st.spinner("PDF okunuyor ve analiz ediliyor..."):
            try:
                pdf_reader = PdfReader(uploaded_file)
                full_text = ""
                for page in pdf_reader.pages:
                    full_text += page.extract_text() or ""

                if len(full_text) < 100:
                    st.warning("Bu PDF'den yeterince metin Ã§Ä±karÄ±lamadÄ±.")
                else:
                    build_index_from_text(full_text)
                    with st.spinner("YanÄ±t oluÅŸturuluyor..."):
                        answer = answer_with_context(question, api_key)
                        st.success("âœ… YanÄ±t:")
                        st.write(answer)
            except Exception as e:
                st.error(f"Hata oluÅŸtu: {str(e)}")

# ğŸ§  HafÄ±zaya DayalÄ± Soru Sekmesi
with tab6:
    streamlit_memory_qa_tab(api_key)

# ğŸ“Œ PDF'yi Milvus HafÄ±zasÄ±na Ekle Sekmesi

# ğŸ“Œ PDF'yi Milvus HafÄ±zasÄ±na Ekle Sekmesi
with tab7:
    st.subheader("ğŸ“Œ PDF'yi Milvus HafÄ±zasÄ±na Ekle")

    user_id = st.text_input("ğŸ‘¤ KullanÄ±cÄ± ID:", value="demo-user")
    uploaded_file = st.file_uploader("ğŸ“ PDF yÃ¼kleyin", type=["pdf"], key="milvus_pdf")

    if uploaded_file and user_id and st.button("ğŸ’¾ HafÄ±zaya Kaydet"):
        with st.spinner("PDF okunuyor ve embedding Milvus'a kaydediliyor..."):
            try:
                pdf_reader = PdfReader(uploaded_file)
                full_text = ""
                for page in pdf_reader.pages:
                    full_text += page.extract_text() or ""

                if len(full_text.strip()) < 100:
                    st.warning("Bu PDF'den yeterince metin Ã§Ä±karÄ±lamadÄ±.")
                else:
                    # ğŸ”¥ PDF uzunluÄŸunu kontrol et ve bÃ¶l
                    words = full_text.split()
                    chunk_size = 500  # yaklaÅŸÄ±k 500 kelimelik parÃ§alar
                    for i in range(0, len(words), chunk_size):
                        chunk = " ".join(words[i:i+chunk_size])
                        title = f"{uploaded_file.name.replace('.pdf', '')}_chunk_{i//chunk_size + 1}"
                        add_to_milvus(user_id=user_id, title=title, text=chunk, api_key=api_key)

                    st.success("âœ… PDF iÃ§eriÄŸi parÃ§alara ayrÄ±ldÄ± ve Milvus'a baÅŸarÄ±yla eklendi!")
            except Exception as e:
                st.error(f"Hata oluÅŸtu: {str(e)}")

# ğŸ” KayÄ±tlÄ± baÅŸlÄ±klarÄ± listeleme sekmesi (isteÄŸe baÄŸlÄ± bir tab ya da sidebar bÃ¶lÃ¼mÃ¼ne eklenebilir)

st.subheader("ğŸ“š KayÄ±tlÄ± BaÅŸlÄ±klarÄ±nÄ±zÄ± GÃ¶rÃ¼ntÃ¼leyin")

current_user_id = st.text_input("ğŸ‘¤ KullanÄ±cÄ± ID (baÅŸlÄ±klarÄ± gÃ¶rmek iÃ§in):", value="demo-user")

if st.button("ğŸ“‚ BaÅŸlÄ±klarÄ± GÃ¶ster") and current_user_id:
    try:
        titles = list_titles(user_id=current_user_id, session_user_id=current_user_id)
        if titles:
            st.success(f"âœ… {len(titles)} baÅŸlÄ±k bulundu:")
            for title in titles:
                st.markdown(f"- ğŸ“„ **{title}**")
        else:
            st.info("ğŸ” HenÃ¼z eklenmiÅŸ bir baÅŸlÄ±k bulunamadÄ±.")
    except PermissionError as e:
        st.error(f"ğŸš« Yetkisiz eriÅŸim: {str(e)}")
    except Exception as e:
        st.error(f"âš ï¸ Bir hata oluÅŸtu: {str(e)}")

