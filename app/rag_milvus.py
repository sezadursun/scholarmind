from app.milvus_engine import search_milvus
from openai import OpenAI

RAG_SYSTEM_MESSAGE = "Sen, sadece iÃ§eriklere dayanarak gÃ¼venilir ve akademik yanÄ±tlar veren bir asistansÄ±n. Uydurma."
AAG_SYSTEM_MESSAGE = "Sen yaratÄ±cÄ±, aÃ§Ä±klayÄ±cÄ± ve analoji temelli bir GPT asistansÄ±n. KavramlarÄ± benzetmelerle aÃ§Ä±kla. Bilimsel ama sade Ã¶rneklerle destekle."

# ğŸ§® RAG + AAG destekli yanÄ±tlayÄ±cÄ±

def answer_question_with_memory(question: str, user_id: str, api_key: str, mode: str = "RAG", top_k: int = 3) -> str:
    """KullanÄ±cÄ± tercihine gÃ¶re RAG veya AAG yanÄ±t dÃ¶ner."""
    top_titles = search_milvus(query=question, user_id=user_id, api_key=api_key, top_k=top_k)
    context = "\n".join([f"- {title}" for title, _ in top_titles])

    if mode == "RAG":
        system_msg = RAG_SYSTEM_MESSAGE
        user_prompt = f"""
AÅŸaÄŸÄ±daki makale baÅŸlÄ±klarÄ± daha Ã¶nceden kullanÄ±cÄ± tarafÄ±ndan eklenmiÅŸtir. Bu baÅŸlÄ±klardaki iÃ§eriklere dayanarak soruyu yanÄ±tla:

Makale baÅŸlÄ±klarÄ±:
{context}

Soru:
{question}

Cevapla:
"""
    else:
        system_msg = AAG_SYSTEM_MESSAGE
        user_prompt = f"""
KullanÄ±cÄ± aÅŸaÄŸÄ±daki soruyu sordu. Soruyu, daha Ã¶nce eklenmiÅŸ makale baÅŸlÄ±klarÄ±na referans vererek benzetmelerle aÃ§Ä±kla:

Makale baÅŸlÄ±klarÄ±:
{context}

Soru:
{question}

YaratÄ±cÄ±, sade ama bilimsel ve etkili bir cevap ver:
"""

    client = OpenAI(api_key=api_key)
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_msg},
            {"role": "user", "content": user_prompt}
        ]
    )
    return response.choices[0].message.content.strip()


# ğŸ§¬ Streamlit entegrasyonu iÃ§in sekme kodu:

def streamlit_memory_qa_tab(api_key: str):
    import streamlit as st
    from app.rag_milvus import answer_question_with_memory

    st.subheader("ğŸ§  HafÄ±zaya DayalÄ± Soru-Cevap (Milvus + GPT-4o)")

    user_id = st.text_input("ğŸ‘¤ KullanÄ±cÄ± ID (size Ã¶zgÃ¼ bir ad girin):", value="demo-user")
    question = st.text_area("â“ Sormak istediÄŸiniz soru:", height=100)

    # KullanÄ±cÄ±ya aÃ§Ä±klamalÄ± seÃ§im sunalÄ±m
    response_mode = st.radio(
        "âœï¸ YanÄ±t tarzÄ±nÄ±zÄ± seÃ§in:",
        ["ğŸ“š Bilgiye DayalÄ± (RAG)", "ğŸ¨ Analojiyle AÃ§Ä±klayan (AAG)"],
        index=0
    )

    with st.expander("â„¹ï¸ RAG ve AAG farkÄ± nedir?"):
        st.markdown("""
**ğŸ“š Bilgiye DayalÄ± YanÄ±t (RAG):**
- YalnÄ±zca daha Ã¶nce eklediÄŸiniz makalelerden iÃ§eriklere bakar.
- Akademik, gÃ¼venilir ve kÄ±sa yanÄ±t verir.

**ğŸ¨ Analojiyle AÃ§Ä±klayan YanÄ±t (AAG):**
- CevabÄ± benzetmelerle aÃ§Ä±klar.
- Konuyu sadeleÅŸtirerek Ã¶rneklerle anlatÄ±r.
        """)

    if st.button("ğŸš€ YanÄ±tla") and question and user_id:
        with st.spinner("ğŸ” En alakalÄ± iÃ§erikler aranÄ±yor ve GPT yanÄ±tÄ± getiriliyor..."):
            try:
                mode = "RAG" if "RAG" in response_mode else "AAG"
                result = answer_question_with_memory(
                    question=question,
                    user_id=user_id,
                    api_key=api_key,
                    mode=mode
                )
                st.success("âœ… YanÄ±t")
                st.write(result)
            except Exception as e:
                st.error(f"âŒ Hata: {str(e)}")

